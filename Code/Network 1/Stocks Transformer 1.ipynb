{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6af7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7826cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim): \n",
    "        super(Embedding, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.input_size = input_size\n",
    "    \n",
    "    #embed the inputs into an embed_dim dimensional embedding space using multiplication by a matrix C\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0) \n",
    "        C = torch.randn((batch_size, self.input_size, self.embed_dim)) \n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[i])):\n",
    "                C[i][j]*=x[i][j]\n",
    "        return C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len, embed_model_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_model_dim\n",
    "        \n",
    "        pe = torch.zeros(max_seq_len, self.embed_dim) \n",
    "        \n",
    "        #calculates positional encoding for each entry in the matrix\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2*i)/self.embed_dim)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.embed_dim)))\n",
    "        \n",
    "        pe = pe.unsqueeze(0) #adds a new dimension to pe\n",
    "        self.register_buffer('pe', pe) #ensures pe not trained by optimiser\n",
    "    \n",
    "    #add positional encoding to the embedding vectors\n",
    "    def forward(self, x):\n",
    "        x *= math.sqrt(self.embed_dim) #increases size of embeddings\n",
    "        seq_len = x.size(1)\n",
    "        x += torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False) #adds constant to embedding\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d72db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.n_heads = n_heads\n",
    "        self.single_head_dim = int(self.embed_dim / self.n_heads) \n",
    "        \n",
    "        self.query_matrix = nn.Linear(self.single_head_dim , self.single_head_dim ,bias=False) \n",
    "        self.key_matrix = nn.Linear(self.single_head_dim  , self.single_head_dim, bias=False) \n",
    "        self.value_matrix = nn.Linear(self.single_head_dim ,self.single_head_dim , bias=False) \n",
    "        \n",
    "        self.out = nn.Linear(self.n_heads*self.single_head_dim ,self.embed_dim) \n",
    "        \n",
    "    def forward(self, key, query, value, mask=None):\n",
    "        batch_size = key.size(0)\n",
    "        seq_length = key.size(1)\n",
    "        seq_length_query = query.size(1)\n",
    "        \n",
    "        #split the input matrices into n_heads heads\n",
    "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim) \n",
    "        query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim)\n",
    "        value = value.view(batch_size, seq_length, self.n_heads, self.single_head_dim)\n",
    "        \n",
    "        #apply the linear layers and then transpose matrices to ensure multiplication across correct dimensions in next step\n",
    "        k = self.key_matrix(key).transpose(1, 2) \n",
    "        q = self.query_matrix(query).transpose(1, 2)   \n",
    "        v = self.value_matrix(value).transpose(1, 2) \n",
    "\n",
    "        #calculate the attention scores, and then multiply by the value matrix\n",
    "        k_adjusted = k.transpose(-1, -2) \n",
    "\n",
    "        product = torch.matmul(q, k_adjusted)\n",
    "        \n",
    "        #apply mask if needed\n",
    "        if mask is not None:\n",
    "            product = product.masked_fill(mask == 0, float(\"-1e20\")) \n",
    "\n",
    "        product = product / math.sqrt(self.single_head_dim) \n",
    "\n",
    "        scores = F.softmax(product, dim=-1)\n",
    "        scores = torch.matmul(scores, v) \n",
    "        \n",
    "        #concatenate the heads and then apply the final linear layer to produce the results\n",
    "        concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads) #32 x 10 x 512\n",
    "\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, dropout_value, expansion_factor = 4, n_heads = 8):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(embed_dim, n_heads)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "                        nn.Linear(embed_dim, expansion_factor * embed_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(expansion_factor * embed_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout_value)\n",
    "        self.dropout2 = nn.Dropout(dropout_value)\n",
    "    \n",
    "    #beings together the elements of the main encoder block\n",
    "    def forward(self, key, query, value):\n",
    "        attention_out = self.attention(key, query, value)\n",
    "        attention_residual_out = attention_out + query\n",
    "        norm1_out = self.dropout1(self.norm1(attention_out))\n",
    "        \n",
    "        feed_fwd_out = self.feed_forward(norm1_out)\n",
    "        feed_fwd_residual_out = feed_fwd_out + norm1_out\n",
    "        norm2_out = self.dropout2(self.norm2(feed_fwd_residual_out))\n",
    "        \n",
    "        return norm2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e574f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    class TransformerEncoder(nn.Module):\n",
    "        def __init__(self, seq_len, input_size, embed_dim, num_layers=2, expansion_factor=4, n_heads=8): ###batch_size after embed dim\n",
    "            super(TransformerEncoder, self).__init__()\n",
    "\n",
    "            self.embedding_layer = Embedding(input_size, embed_dim) ###batch_size was first arg\n",
    "            self.positional_encoder = PositionalEmbedding(seq_len, embed_dim)\n",
    "\n",
    "            self.layers = nn.ModuleList([TransformerBlock(embed_dim, dropout_value, expansion_factor, n_heads) for i in range(num_layers)])\n",
    "        \n",
    "        #a full run through of the encoder by embedding the inputs and then applying the main encoder block num_layers times\n",
    "        def forward(self, x):\n",
    "            embed_out = self.embedding_layer(x)\n",
    "            out = self.positional_encoder(embed_out)\n",
    "            for layer in self.layers:\n",
    "                out = layer(out, out, out)\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb680230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, dropout_value, expansion_factor=4, n_heads=8):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(embed_dim, n_heads=8)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, dropout_value, expansion_factor, n_heads)\n",
    "    \n",
    "    #brings together the elements in the main decoder block, \n",
    "    #masked multi-head attention and then the elements already defined in transformer_block\n",
    "    #this time using the appropriate inputs for encoder-decoder multi-head attention\n",
    "    def forward(self, key, x, value, mask):\n",
    "        attention = self.attention(x, x, x, mask=mask)\n",
    "        x = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(key, x, value)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bd153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, decoder_input_size, embed_dim, seq_len, target_output_size, dropout_value, num_layers=2, expansion_factor=4, n_heads=8): ###batch size after target output\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = Embedding(decoder_input_size, embed_dim) ###batch size first arg\n",
    "        self.position_embedding = PositionalEmbedding(seq_len, embed_dim)\n",
    "        self.fst_attention = DecoderBlock(embed_dim, dropout_value, expansion_factor=4, n_heads=8)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_dim, dropout_value, expansion_factor=4, n_heads=8) \n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "\n",
    "        )\n",
    "        self.fc1_out = nn.Linear(embed_dim, 1)\n",
    "        self.fc2_out = nn.Linear(decoder_input_size, target_output_size)\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "    \n",
    "    #full run through of the decoder\n",
    "    def forward(self, x, enc_out, mask):\n",
    "        x = self.embedding(x) #16 x 9 x 32\n",
    "        x = self.position_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(enc_out, x, enc_out, mask=None)\n",
    "        \n",
    "        out = self.fc1_out(x)\n",
    "        out = torch.squeeze(out)\n",
    "        out = self.fc2_out(out)\n",
    "        out = torch.squeeze(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e363f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, embed_dim, input_size, decoder_input_size, target_output_size, seq_length,num_layers=2, dropout_value=0.2, expansion_factor=4, n_heads=8): ###batch_size, after target output\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.decoder_input_size = decoder_input_size\n",
    "        \n",
    "        self.encoder = TransformerEncoder(seq_length, input_size, embed_dim, num_layers=num_layers, expansion_factor=expansion_factor, n_heads=n_heads) ###batch_size=batch_size, after embed dim\n",
    "        self.decoder = TransformerDecoder(decoder_input_size, embed_dim, seq_length, target_output_size, dropout_value, num_layers=num_layers, expansion_factor=expansion_factor, n_heads=n_heads) ###batch_size=batch_size, after target output\n",
    "        \n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(batch_size, 1, trg_len, trg_len) #returns lower triangular matrix\n",
    "        return trg_mask\n",
    "    \n",
    "    def decode(self, src, trg):\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_out = self.encoder(src)\n",
    "        out_labels = []\n",
    "        batch_size, seq_len = src.shape[0], src.shape[1]\n",
    "        \n",
    "        out = trg\n",
    "        for i in range(seq_len):\n",
    "            out = self.decoder(out, enc_out, trg_mask)\n",
    "            \n",
    "            out = out[:, -1, :]\n",
    "            \n",
    "            out = out.argmax(-1)\n",
    "            out_labels.append(out.item())\n",
    "            out = torch.unsqueeze(out, axis=0)\n",
    "            \n",
    "        return out_labels\n",
    "    \n",
    "    #brings the encoder and decoder together to produce the network outputs\n",
    "    def forward(self, src, trg):\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_out = self.encoder(src) #16 x 10 x 32\n",
    "        \n",
    "        outputs = self.decoder(trg, enc_out, trg_mask) #16 x 9, 16 x 10 x 32, 16 x 1 x 9 x 9 \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15256046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model and model parameters\n",
    "input_size = 10\n",
    "decoder_input_size = 9\n",
    "target_output_size = 1\n",
    "num_layers = 6\n",
    "seq_length = 10 \n",
    "batch_size = 16\n",
    "dropout_value = 0.2\n",
    "num_training_stocks = 5\n",
    "\n",
    "\n",
    "model = Transformer(embed_dim=32, input_size=input_size, \n",
    "                    decoder_input_size=decoder_input_size, target_output_size=target_output_size, seq_length=seq_length,\n",
    "                    num_layers=num_layers, dropout_value=dropout_value, expansion_factor=4, n_heads=8) \n",
    "\n",
    "#adjust to the path of this program\n",
    "current_path = os.path.join('')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59feb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dataset of inputs paired with labels\n",
    "class CustomDataset():\n",
    "    def __init__(self, inputs, labels, transform=None, target_transform=None):\n",
    "        self.labels = labels\n",
    "        self.inputs = inputs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inpt = self.inputs[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            inpt = self.transform(inpt)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return inpt, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9fff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "#input the path to the stocks data used\n",
    "mypath = os.path.join(current_path, '..', '..', 'Data', 'Network 1 data', 'Stocks')\n",
    "stocks = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "Xtr, Ytr = [], []\n",
    "Xval, Yval = [], []\n",
    "Xte, Yte = [], []\n",
    "\n",
    "block_size = input_size\n",
    "\n",
    "#builds dataset of 10 consecutive days for input paired with the next day for label\n",
    "def build_dataset(prices):\n",
    "            X, Y = [], []\n",
    "            if len(prices)<block_size+1:\n",
    "                return [], []\n",
    "            for i in range(len(prices)-block_size):\n",
    "                X.append(prices[i:i+block_size])\n",
    "                Y.append(prices[i+block_size])\n",
    "            X = torch.tensor(X)\n",
    "            Y = torch.tensor(Y)\n",
    "            return X, Y\n",
    "\n",
    "#build the dataset\n",
    "for stock in stocks[1:num_training_stocks+1]:\n",
    "    data = open(os.path.join(mypath, stock)).read().splitlines()[1:]\n",
    "    print(stock)\n",
    "\n",
    "    year_lookup = {}\n",
    "    for day in data:\n",
    "        lst = day.split(',')\n",
    "        year = int(lst[0][:4])\n",
    "        closing = float(lst[4])\n",
    "        if year not in year_lookup.keys():\n",
    "            year_lookup[year] = [closing]\n",
    "        else:\n",
    "            year_lookup[year].append(closing)\n",
    "    \n",
    "    prices = []\n",
    "    train_prices = []\n",
    "    validation_prices = []\n",
    "    test_prices = []\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    years = list(year_lookup.keys())\n",
    "    if stock == stocks[num_training_stocks]:\n",
    "        for year in years:\n",
    "            test_prices += year_lookup[year]\n",
    "            prices += year_lookup[year]\n",
    "    else:\n",
    "        training_cut_off = years[math.ceil(0.75*len(years))-1]\n",
    "        for year in range(years[0], training_cut_off):\n",
    "            train_prices+=year_lookup[year]\n",
    "            prices += year_lookup[year]\n",
    "\n",
    "        for year in range(training_cut_off, years[-1]):\n",
    "            validation_prices+=year_lookup[year]\n",
    "            prices += year_lookup[year]\n",
    "\n",
    "    Xtr += build_dataset(train_prices)[0]\n",
    "    Ytr += build_dataset(train_prices)[1]\n",
    "    Xval += build_dataset(validation_prices)[0]\n",
    "    Yval += build_dataset(validation_prices)[1]\n",
    "    Xte, Yte = build_dataset(test_prices)\n",
    "training_data = CustomDataset(Xtr, Ytr)\n",
    "val_data = CustomDataset(Xval, Yval)\n",
    "test_data = CustomDataset(Xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data in pytorch Dataloaders\n",
    "trainloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e18fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "epochs = 500\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "for e in range(1, epochs+1):\n",
    "    start_time = time.time()\n",
    "    tot_train_loss = 0\n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        if len(y) != batch_size:\n",
    "            continue\n",
    "        trg = x[:, 1:]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(x, trg)\n",
    "        loss = criterion(outputs, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot_train_loss += loss.item()\n",
    "    \n",
    "    #complete running tests on validation data to check how well the training is going\n",
    "    else:\n",
    "        tot_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y in valloader:\n",
    "                if len(y) != batch_size:\n",
    "                    continue\n",
    "                trg = x[:, 1:]\n",
    "                outputs = model(x, trg)\n",
    "                loss = criterion(outputs, y)\n",
    "                tot_val_loss += loss.item()#\n",
    "\n",
    "                \n",
    "        train_loss = tot_train_loss / len(trainloader.dataset)\n",
    "        val_loss = tot_val_loss / len(valloader.dataset)\n",
    "\n",
    "        # At completion of epoch print training/validation losses to check progress\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_loss),\n",
    "              \"Test Loss: {:.3f}.. \".format(val_loss), \n",
    "              \"Time taken: {:.3f}..\".format(time.time()-start_time))\n",
    "    \n",
    "    #after every 10 epochs, save parameters to a checkpoint to ensure nothing is lost if training is not able to complete\n",
    "    if e%10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(current_path, \"Checkpoints\", \"Without Smoothing\", '1checkpoint' + str(e) + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a checkpoints\n",
    "checkpoint = 890\n",
    "state_dict = torch.load(os.path.join(current_path, 'Checkpoints' 'Without Smoothing' + str(checkpoint) + '.pth'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#test results\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inpt = [x for x in test_data[0][0]]\n",
    "    out = [x for x in test_data[0][0]]\n",
    "    for i in range(len(test_data)-10):\n",
    "        x = test_data[i][0]\n",
    "        y = test_data[i][1]\n",
    "        x = x.unsqueeze(0)\n",
    "        trg = x[:, 1:]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, trg)\n",
    "        out.append(output)\n",
    "        inpt.append(test_data[i][1])\n",
    "    \n",
    "\n",
    "\n",
    "total_loss = 0.0\n",
    "for i in range(len(inpt)-10):\n",
    "    outpt = out[i+10].unsqueeze(0)\n",
    "    total_loss += (inpt[i+10]-out[i+10])**2\n",
    "print(total_loss/(len(inpt)-10))\n",
    "plt.plot(inpt, label='real data')\n",
    "plt.plot(out, alpha=0.5, label='predicted values')\n",
    "plt.xlabel('Days', fontsize=15)\n",
    "plt.ylabel('Closing Price', fontsize=15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
